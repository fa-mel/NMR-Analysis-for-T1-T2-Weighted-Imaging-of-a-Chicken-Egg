"""
NMR Analysis for T1/T2 Weighted Imaging of a Chicken Egg

This script provides a complete pipeline for analyzing NMR relaxation data
from egg yolk and albumen samples. It performs the following steps:
1.  Loads and parses raw data files generated by UPENWin software.
2.  Calculates T1 and T2 relaxation times using two methods:
    a) Mono-exponential fitting of the signal decay curve.
    b) Weighted average from the Inverse Laplace Transform (ILT) distribution.
3.  Generates plots comparing the signal curves and relaxation distributions.
4.  Uses the calculated relaxation times to determine the optimal TR and TE
    parameters for maximizing T1-weighted and T2-weighted contrast in a
    Spin-Echo imaging sequence.
5.  Outputs summary tables in both plain text and LaTeX format.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit

class NmrAnalysisPipeline:
    """
    A class to encapsulate the entire NMR data analysis workflow.
    """
    def __init__(self, file_paths):
        """
        Initializes the pipeline with paths to the data files.

        Args:
            file_paths (dict): A dictionary mapping (sample, type) tuples
                               to their corresponding file paths.
        """
        self.file_paths = file_paths
        self.analysis_results = {}
        self.final_relaxation_times = {}

    @staticmethod
    def _model_exponential_decay(t, s0, T, c):
        """
        Three-parameter mono-exponential decay model for fitting relaxation curves.

        Args:
            t (np.ndarray): Time data.
            s0 (float): Initial signal amplitude.
            T (float): Relaxation time constant (T1 or T2).
            c (float): Signal offset.

        Returns:
            np.ndarray: The calculated signal decay.
        """
        return s0 * np.exp(-t / T) + c

    @staticmethod
    def _model_spin_echo_signal(T1, T2, TR, TE, M0=1.0):
        """
        Calculates the signal intensity for a Spin-Echo sequence.

        Args:
            T1 (float): Longitudinal relaxation time.
            T2 (float): Transverse relaxation time.
            TR (np.ndarray): Repetition Time(s).
            TE (np.ndarray): Echo Time(s).
            M0 (float, optional): Equilibrium magnetization. Defaults to 1.0.

        Returns:
            np.ndarray: The calculated signal intensity.
        """
        # Ensure arrays for vectorized operations
        TR, TE = np.array(TR), np.array(TE)
        # Avoid division by zero if TE is 0
        TE[TE == 0] = 1e-9

        # Full Spin-Echo signal equation
        term1 = 1 - 2 * np.exp(-(TR - TE / 2) / T1) + np.exp(-TR / T1)
        term2 = np.exp(-TE / T2)
        return M0 * term1 * term2

    def _analyze_single_file(self, file_path):
        """
        Loads, parses, and analyzes a single UPENWin .dat file.
        """
        column_names = [
            'T', 'Sig_Np', 'Rate', 'Pct_Np', 'CumPct',
            'SigT', 'E_SNR', 'Sig', 'SigCalc'
        ]
        try:
            data = pd.read_csv(
                file_path, sep=',', header=None,
                names=column_names, usecols=range(9)
            )
            numeric_cols = ['T', 'Sig_Np', 'SigT', 'Sig', 'SigCalc']
            for col in numeric_cols:
                data[col] = pd.to_numeric(data[col], errors='coerce')
            data.dropna(subset=numeric_cols, inplace=True)
        except (FileNotFoundError, ValueError):
            return None

        if data.empty:
            return None

        results = {'raw_data': data}
        x_data, y_data = data['SigT'].to_numpy(), data['Sig'].to_numpy()

        # Perform mono-exponential fit
        try:
            # Sensible initial guesses for the fit parameters [S0, T, offset]
            p0 = [
                y_data[0] - y_data.iloc[-1],
                data.loc[data['Sig_Np'].idxmax()]['T'],
                y_data.iloc[-1]
            ]
            params, covariance = curve_fit(
                self._model_exponential_decay, x_data, y_data, p0=p0,
                bounds=([0, 0, -np.inf], [np.inf, np.inf, np.inf]),
                maxfev=5000
            )
            errors = np.sqrt(np.diag(covariance))
            results['fit'] = {'params': params, 'errors': errors}
        except (RuntimeError, ValueError):
            results['fit'] = None

        # Calculate weighted average from distribution
        dist_T = data['T']
        dist_Sig_Np = data['Sig_Np']
        sum_sig_np = dist_Sig_Np.sum()
        if not dist_Sig_Np.empty and sum_sig_np > 0:
            weighted_T = np.sum(dist_T * dist_Sig_Np) / sum_sig_np
            # Uncertainty of the weighted mean
            weighted_T_err = np.sqrt(1 / sum_sig_np)
            results['distrib'] = {'params': (weighted_T, weighted_T_err)}

        return results

    def _plot_single_analysis(self, results, sample_name, measurement_type):
        """
        Generates and displays plots for a single analysis run.
        """
        if not results:
            print(f"Plotting failed for {sample_name} {measurement_type}: No results.")
            return

        data = results['raw_data']
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
        fig.suptitle(f'Analysis for {sample_name} - {measurement_type} Measurement', fontsize=16)

        # Plot 1: Signal Curve
        ax1.plot(data['SigT'], data['Sig'], 'o', label='Measured Data')
        if results.get('fit'):
            params = results['fit']['params']
            errors = results['fit']['errors']
            fit_label = f'{measurement_type} = ({params[1]:.1f} Â± {errors[1]:.1f}) ms'
            ax1.plot(data['SigT'], self._model_exponential_decay(data['SigT'], *params),
                     'r-', linewidth=2, label=f'Fitted Curve\n({fit_label})')
        
        ax1.plot(data['SigT'], data['SigCalc'], 'g--', linewidth=2, label='Theoretical Line (SigCalc)')

        ax1.set_title(f'{measurement_type} Signal Curve')
        ax1.set_xlabel('Time (ms)')
        ax1.set_ylabel('Signal Intensity (a.u.)')
        ax1.legend()
        ax1.grid(True, linestyle="--")
        if measurement_type == 'T2':
            ax1.set_yscale('log')

        # Plot 2: Relaxation Time Distribution
        ax2.semilogx(data['T'], data['Sig_Np'], '-', label=f'{measurement_type} Distribution')
        ax2.set_title(f'{measurement_type} Distribution')
        ax2.set_xlabel(f'{measurement_type} (ms)')
        ax2.set_ylabel('Signal Density (a.u.)')
        ax2.legend()
        ax2.grid(True, linestyle="--")

        plt.tight_layout(rect=[0, 0.03, 1, 0.95])
        plt.show()

    def _plot_optimal_parameters(self):
        """
        Calculates and plots the optimal imaging parameters for contrast.
        """
        t_vals = self.final_relaxation_times
        
        # T1-weighted optimization
        TE_fixed_for_T1w = 10.0
        TR_range = np.linspace(1, 2000, 500)
        sig_yolk_t1w = self._model_spin_echo_signal(t_vals['Yolk']['T1'], t_vals['Yolk']['T2'], TR_range, TE_fixed_for_T1w)
        sig_albumen_t1w = self._model_spin_echo_signal(t_vals['Albumen']['T1'], t_vals['Albumen']['T2'], TR_range, TE_fixed_for_T1w)
        contrast_t1w = np.abs(sig_yolk_t1w - sig_albumen_t1w)
        optimal_TR = TR_range[np.argmax(contrast_t1w)]

        # T2-weighted optimization
        TR_fixed_for_T2w = 3000.0
        TE_range = np.linspace(10, 800, 500)
        sig_yolk_t2w = self._model_spin_echo_signal(t_vals['Yolk']['T1'], t_vals['Yolk']['T2'], TR_fixed_for_T2w, TE_range)
        sig_albumen_t2w = self._model_spin_echo_signal(t_vals['Albumen']['T1'], t_vals['Albumen']['T2'], TR_fixed_for_T2w, TE_range)
        contrast_t2w = np.abs(sig_yolk_t2w - sig_albumen_t2w)
        optimal_TE = TE_range[np.argmax(contrast_t2w)]

        # Plotting
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
        fig.suptitle('Imaging Parameter Optimization', fontsize=16)

        ax1.plot(TR_range, sig_yolk_t1w, label='Yolk Signal')
        ax1.plot(TR_range, sig_albumen_t1w, label='Albumen Signal')
        ax1.plot(TR_range, contrast_t1w, 'r--', label='Contrast')
        ax1.axvline(x=optimal_TR, color='k', linestyle=':', label=f'Optimal TR = {optimal_TR:.1f} ms')
        ax1.set_title(f'T1 Contrast Opt. (fixed TE={TE_fixed_for_T1w} ms)')
        ax1.set_xlabel('Repetition Time (TR) [ms]')
        ax1.set_ylabel('Normalized Signal (a.u.)')
        ax1.legend()
        ax1.grid(True)

        ax2.plot(TE_range, sig_yolk_t2w, label='Yolk Signal')
        ax2.plot(TE_range, sig_albumen_t2w, label='Albumen Signal')
        ax2.plot(TE_range, contrast_t2w, 'r--', label='Contrast')
        ax2.axvline(x=optimal_TE, color='k', linestyle=':', label=f'Optimal TE = {optimal_TE:.1f} ms')
        ax2.set_title(f'T2 Contrast Opt. (fixed TR={TR_fixed_for_T2w} ms)')
        ax2.set_xlabel('Echo Time (TE) [ms]')
        ax2.set_ylabel('Normalized Signal (a.u.)')
        ax2.legend()
        ax2.grid(True)
        
        plt.show()

    def run(self):
        """
        Executes the full analysis pipeline.
        """
        # --- PHASE 1: Analyze individual files ---
        print("#" * 60)
        print(">>> PHASE 1: ANALYZING RELAXATION DATA <<<")
        print("#" * 60)
        for (sample, m_type), f_path in self.file_paths.items():
            print(f"\n>>> Analyzing {sample} {m_type} from {f_path} <<<")
            res = self._analyze_single_file(f_path)
            self.analysis_results[(sample, m_type)] = res
            self._plot_single_analysis(res, sample, m_type)

        # --- PHASE 2: Generate summary reports ---
        print("\n\n" + "#" * 60)
        print(">>> PHASE 2: GENERATING FINAL REPORTS <<<")
        print("#" * 60)
        
        table_data = []
        for (sample, m_type), m_res in self.analysis_results.items():
            if not m_res:
                continue
            
            if sample not in self.final_relaxation_times:
                self.final_relaxation_times[sample] = {}
            
            fit_res = m_res.get('fit')
            dist_res = m_res.get('distrib')

            fit_val_str = f"({fit_res['params'][1]:.3e} \\pm {fit_res['errors'][1]:.1e})" if fit_res else "Fit Failed"
            dist_val_str = f"({dist_res['params'][0]:.3e} \\pm {dist_res['params'][1]:.1e})" if dist_res else "N/A"
            
            table_data.append({
                'Sample': sample,
                'Parameter': f'${m_type}$',
                'Fit Value (ms)': fit_val_str,
                'Distribution Value (ms)': dist_val_str
            })
            
            if dist_res:
                self.final_relaxation_times[sample][m_type] = dist_res['params'][0]

        results_df = pd.DataFrame(table_data).sort_values(
            by=['Sample', 'Parameter'], ascending=[True, False]
        ).reset_index(drop=True)

        print("\n--- Text Summary Table ---\n")
        print(results_df.to_string(index=False))
        print("\n\n--- LaTeX Code for Report ---\n")
        print(results_df.to_latex(
            index=False,
            caption='Summary of relaxation times.',
            label='tab:results',
            column_format='llcc',
            escape=False
        ))

        # --- PHASE 3: Calculate and plot optimal parameters ---
        print("\n\n" + "#" * 60)
        print(">>> PHASE 3: CALCULATING OPTIMAL IMAGING PARAMETERS <<<")
        print("#" * 60)

        if all(k in self.final_relaxation_times.get(s, {}) for s in ['Yolk', 'Albumen'] for k in ['T1', 'T2']):
            self._plot_optimal_parameters()
        else:
            print("\nCould not proceed to imaging parameter calculation due to missing T1/T2 values.")


if __name__ == '__main__':
    # Define the file paths for the NMR data
    # IMPORTANT: Ensure these .dat files are in the same directory as the script
    file_paths = {
        ('Yolk', 'T2'): 'CPMGtuorlo1B.dat',
        ('Albumen', 'T2'): 'CPMGalbume1B.dat',
        ('Yolk', 'T1'): 'IRtuorloH.dat',
        ('Albumen', 'T1'): 'IRalbumeH.dat'
    }

    # Create and run the analysis pipeline
    pipeline = NmrAnalysisPipeline(file_paths)
    pipeline.run()
